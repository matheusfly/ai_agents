#!/usr/bin/env python3
"""
Quick fix script for Ollama connection issues.
"""
import os
import sys
import subprocess
import platform
import time


def check_ollama_installed():
    """Check if Ollama is installed."""
    try:
        result = subprocess.run(["ollama", "--version"], 
                              capture_output=True, text=True, timeout=5)
        return result.returncode == 0
    except:
        return False


def check_ollama_running():
    """Check if Ollama is running."""
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=3)
        return response.status_code == 200
    except:
        return False


def start_ollama():
    """Start Ollama service."""
    system = platform.system().lower()
    
    print("üîÑ Starting Ollama service...")
    
    try:
        if system == "windows":
            # Try to start Ollama on Windows
            subprocess.Popen(["ollama", "serve"], shell=True, 
                           creationflags=subprocess.CREATE_NEW_CONSOLE)
        else:
            # Unix-like systems
            subprocess.Popen(["ollama", "serve"])
        
        # Wait for service to start
        print("‚è≥ Waiting for Ollama to start...")
        for i in range(15):
            if check_ollama_running():
                print("‚úÖ Ollama is now running!")
                return True
            time.sleep(1)
        
        print("‚ö†Ô∏è  Ollama may be starting in the background...")
        return False
        
    except Exception as e:
        print(f"‚ùå Error starting Ollama: {e}")
        return False


def pull_basic_model():
    """Pull a basic model for testing."""
    print("üì¶ Pulling a basic model for testing...")
    
    try:
        # Try to pull a small, fast model
        result = subprocess.run(
            ["ollama", "pull", "llama3.2:1b"], 
            capture_output=True, text=True, timeout=300
        )
        
        if result.returncode == 0:
            print("‚úÖ Successfully pulled llama3.2:1b model")
            return True
        else:
            print("‚ö†Ô∏è  Failed to pull model, but Ollama should still work")
            return False
            
    except subprocess.TimeoutExpired:
        print("‚è∞ Model pull is taking longer than expected (this is normal)")
        print("üîÑ The model will continue downloading in the background")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Error pulling model: {e}")
        return False


def main():
    """Main quick fix function."""
    print("üöë Quick Fix for Ollama Connection Issues")
    print("=" * 45)
    
    # Check if Ollama is installed
    if not check_ollama_installed():
        print("‚ùå Ollama is not installed!")
        print("üîß Please install Ollama first:")
        print("   ‚Ä¢ Windows: Download from https://ollama.com/download")
        print("   ‚Ä¢ macOS: brew install ollama")
        print("   ‚Ä¢ Linux: curl -fsSL https://ollama.com/install.sh | sh")
        print("")
        print("üí° Or run: python setup_ollama.py for automated installation")
        return False
    
    print("‚úÖ Ollama is installed")
    
    # Check if Ollama is running
    if check_ollama_running():
        print("‚úÖ Ollama is already running!")
        print("üéâ Your system should work now!")
        return True
    
    print("‚ö†Ô∏è  Ollama is not running")
    
    # Try to start Ollama
    if start_ollama():
        print("‚úÖ Ollama started successfully!")
        
        # Try to pull a basic model
        pull_basic_model()
        
        print("\nüéâ Quick fix completed!")
        print("üöÄ Your Multi-Agent system should now work!")
        print("üìù Run 'python start_system.py' to test")
        return True
    else:
        print("‚ùå Failed to start Ollama automatically")
        print("üîß Please try manually:")
        print("   1. Open a new terminal/command prompt")
        print("   2. Run: ollama serve")
        print("   3. Keep that terminal open")
        print("   4. Run your system again")
        return False


if __name__ == "__main__":
    success = main()
    
    if not success:
        print("\nüÜò Still having issues?")
        print("üí¨ Common solutions:")
        print("   ‚Ä¢ Restart your terminal/command prompt")
        print("   ‚Ä¢ Check if port 11434 is available")
        print("   ‚Ä¢ Try running as administrator (Windows)")
        print("   ‚Ä¢ Check firewall settings")
        print("   ‚Ä¢ Run: python setup_ollama.py for full setup")
    
    input("\nPress Enter to exit...")
